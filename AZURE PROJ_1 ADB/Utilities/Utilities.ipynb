{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be9774f3-1424-45c6-b2d6-e87bdeb92cdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def pre_schema(path):\n",
    "    try:\n",
    "        df=spark.read.format(\"delta\").load(f\"{path}\").limit(1)\n",
    "        schema=\"\"\n",
    "        for i in df.dtypes:\n",
    "            schema=schema+i[0]+\" \"+i[1]+\",\"\n",
    "        return schema[0:-1]\n",
    "    except Exception as e:\n",
    "        print(\"Error in pre_schema: \",str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6fb1146-740a-45da-9701-473cdf27f84d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def f_delta_cleansed_load(table_name, location, database_name):\n",
    "    try:\n",
    "        schema=pre_schema(location)\n",
    "        query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS hive_metastore.{3}.{0} ({2}) \n",
    "            USING DELTA \n",
    "            LOCATION '{1}'\n",
    "        \"\"\".format(table_name, location, schema, database_name)\n",
    "        spark.sql(query)\n",
    "    except Exception as e:\n",
    "        print(\"Error in f_delta_cleansed_load: \", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee6a3ceb-0bfb-4e3f-a859-3a5a31747909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%py\n",
    "def f_count_check(database, operation_type, table_name, number_diff):\n",
    "    # Create a temporary view of the table's history\n",
    "    spark.sql(f\"DESC HISTORY {database}.{table_name}\").createOrReplaceTempView(\"Table_count\")\n",
    "    \n",
    "    # Get the current count of rows for the latest operation of the specified type\n",
    "    count_current = spark.sql(f\"\"\"\n",
    "        SELECT operationMetrics.numOutputRows \n",
    "        FROM Table_count \n",
    "        WHERE version = (\n",
    "            SELECT MAX(version) \n",
    "            FROM Table_count \n",
    "            WHERE TRIM(LOWER(operation)) = LOWER('{operation_type}')\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Determine the final current count\n",
    "    if count_current.first() is None:\n",
    "        final_count_current = 0\n",
    "    else:\n",
    "        final_count_current = int(count_current.first().numOutputRows)\n",
    "    \n",
    "    # Get the previous count of rows before the latest operation of the specified type\n",
    "    count_previous = spark.sql(f\"\"\"\n",
    "        SELECT operationMetrics.numOutputRows \n",
    "        FROM Table_count \n",
    "        WHERE version < (\n",
    "            SELECT version \n",
    "            FROM Table_count \n",
    "            WHERE LOWER(TRIM(operation)) = LOWER('{operation_type}') \n",
    "            ORDER BY version DESC \n",
    "            LIMIT 1\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Determine the final previous count\n",
    "    if count_previous.first() is None:\n",
    "        final_count_previous = 0\n",
    "    else:\n",
    "        final_count_previous = int(count_previous.first().numOutputRows or 0)\n",
    "    \n",
    "    # Check if the difference between current and previous counts exceeds the threshold\n",
    "    if (final_count_current - final_count_previous) > number_diff:\n",
    "        raise Exception(f\"Difference is huge in {table_name} {final_count_current - final_count_previous}\")\n",
    "    else:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 532962775370568,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Utilities",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
